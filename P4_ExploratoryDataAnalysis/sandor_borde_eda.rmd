Explore financial contribution of presidential election of California by Sándor Bordé
========================================================

```{r global_options, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(gridExtra)
```

```{r echo=FALSE, Load_the_Data}
# Load the Data
finData <- read.csv('support_CA_col.csv')
```

This dataset contains individual donations to the candidates of the Presidential 
Election in 2016. For each data entry, we have the amount of contribution, 
sender, the name of the candidate, date, note, etc.
I have 1,304,346 entry in the dataset.

# Dataset description

```{r echo=FALSE, Variables_list}
str(finData)
```
```{r echo=FALSE, Summary}
summary(finData)
```

The dataset contains 1,304,346 contribution's data; each entry has 18 variables.

# Data transformation

There are meaningless or not so informative variables: 

  * *cand_id*: this is redundant if we want to use the name of the candidate too. 
  * *contbr_st*: my dataset contains only data from CA, so it is meaningless.
  * *memo_text*, *receipt_desc*: description of the receipt contains textual data which 
I won't analyze. Besides that, in most cases this field is empty.
  * *memo_cd*: this field only indicates that they provided any memo text.
  * *form_tp*, *file_num*, *tran_id*: these variables serve only administrative purposes, 
 but don't provide any meaningful information.
 
I decided to remove the above variables, so I have ten variables left.

```{r echo=FALSE}
finData = subset(finData, select = -c(cand_id, contbr_st, memo_text, 
                                       receipt_desc, memo_cd, form_tp,
                                       file_num, tran_id))
```

After removing the mentioned features, I got the following ten features.

```{r echo=FALSE, Name_list}
names(finData)
```

```{r echo=FALSE}
sum(finData$contb_receipt_amt < 0) / nrow(finData)
```

In my dataset occurred some negative value (which means refund for the 
contributor) what I ignored because I wanted to look at the contribution. 
Negative values made up only the 1.2% of the whole dataset; so I decided to 
remove them from the further analysis.

```{r echo=FALSE, Remove_negative}
finData <- finData[(finData$contb_receipt_amt > 0), ]
```

# Univariate plots section

My primary interest is the distribution of the contribution amount along 
different factors. After plotting the amount distribution histogram, I found
that there can be outliers which fall far from the most of the values. To see 
the distribution better, I adjusted the axis limits.

```{r echo=FALSE, warning = FALSE}
ggplot(finData, aes((contb_receipt_amt))) +
  geom_histogram(binwidth = 1) +
  xlim(0, 250)
```

As we can see from the initial histogram, supporters tended to give specific 
amount of contribution like \$5, \$10, \$50. But besides this fact, such a small
binsize isn't very informative; so I adjusted the histogram further.

```{r echo=FALSE, warning = FALSE}
ggplot(finData, aes((contb_receipt_amt))) +
  geom_histogram(binwidth = 0.5) + 
  scale_x_log10()
```

When I transformed the x-axis to log scale, I found that this dataset follows a
long-tailed, log-normal distribution.

```{r echo=FALSE, warning = FALSE}
ggplot(finData, aes(cand_nm)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

From the plot above we can see, that only a small fraction of the candidates 
received most of the contributions. 

```{r echo=FALSE, warning=FALSE}
# Sum number of contribution by candidate
ratio_by_cand <- finData %>%
  group_by(cand_nm) %>%
  summarise(n = n(), 
            ratio = n() / nrow(finData)) %>%
  arrange(desc(n))
# Calculate cumulative ratio of contribution
ratio_by_cand$cumulative_ratio <- with(ratio_by_cand, cumsum(ratio))
head(ratio_by_cand[, c('cand_nm', 'cumulative_ratio')])
```

We have 25 candidates in the dataset, but four of them received the 95% of 
the contributions.

```{r echo=FALSE, warning=FALSE}
# Count contribution by name of the sender
ratio_by_contbr <- finData %>%
  group_by(contbr_nm) %>%
  summarise(avg = mean(contb_receipt_amt), sum = sum(contb_receipt_amt), n = n()) %>%
  arrange()
# Count contribution by commitee ID
ratio_by_commt <- finData %>%
  group_by(cmte_id) %>%
  summarise(avg = mean(contb_receipt_amt), sum = sum(contb_receipt_amt), n = n()) %>%
  arrange()
# Count contribution by city
ratio_by_city <- finData %>%
  group_by(contbr_city) %>%
  summarise(avg = mean(contb_receipt_amt), sum = sum(contb_receipt_amt), n = n()) %>%
  arrange()
```

```{r echo=FALSE, warning=FALSE}
p1 <- ggplot(ratio_by_contbr, aes(n)) +
  geom_histogram(binwidth = 10) +
  scale_y_log10()

p2 <- ggplot(ratio_by_commt, aes(n)) +
  geom_histogram(binwidth = 0.6) +
  scale_x_log10()

grid.arrange(p1, p2, ncol = 2)
```

I have summed the number contributions per person. I can see that a very high 
portion supported the selected candidate only once. But, there is a couple of 
people who donated to his or her favorite candidate more than 200 times.

After counting the number of contributions by committees, I found that it 
follows a log-normal distribution. That is, most of the committees sent a few 
support, and some of them sent many times.

```{r echo=FALSE, warning=FALSE, message=FALSE}
ggplot(ratio_by_city, aes(n)) + 
  geom_histogram() + 
  scale_x_log10()
```

```{r echo=FALSE, warning=FALSE}
summary(ratio_by_city$n)
```

We can see that this feature doesn't follow log-normal, but long-tail distribution.

```{r echo=FALSE, warning = FALSE}
# Find occupation with 1% or more participation
ratio_by_occupation <- finData %>%
  group_by(contbr_occupation) %>%
  summarise(n = n(), sum = sum(contb_receipt_amt), avg = mean(contb_receipt_amt), ratio = n/nrow(finData)) %>%
  filter(ratio >= 0.01) %>%
  arrange(desc(n))
head(ratio_by_occupation[, c("contbr_occupation", "n", "ratio")], n = 15)
```

In my dataset, there are 28622 different occupation type. But after counting 
the number of contribution, I found that only 11 occupation has at least 
1% ratio, so it follows a long-tail distribution too.

```{r echo=FALSE, warning=FALSE}
ggplot(ratio_by_occupation, aes(contbr_occupation, ratio)) + 
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

One interesting fact that about 20% of the contributions came from retirees, 
the second largest group (almost 10%) was the unemployed people. Besides that, 
most of the top 11 occupation was some white-collar job: attorney, consultant, 
engineer etc.

```{r echo=FALSE, warning=FALSE}
ratio_by_election <- finData %>%
  filter(election_tp != '') %>%
  group_by(election_tp) %>%
  summarise(n = n(), raio = n() / nrow(finData)) %>%
  arrange(desc(n))
              
ggplot(ratio_by_election, aes(x = '', y = n, fill = election_tp)) +
  geom_bar(width = 1, stat = "identity") + 
  coord_polar(start = 0, "y")
```

Almost every contribution have been made for the 2016 primary and general election.
Because the other two (primary 2020 and other 2016) was so small I decided not 
to use them in the further analysis.

```{r echo=FALSE, warning=FALSE}
# Count contribution by date
ratio_by_date <- finData %>%
  group_by(date = as.Date(contb_receipt_dt, "%d-%b-%Y")) %>%
  summarise(n = n(), raio = n() / nrow(finData)) %>%
  arrange()

ggplot(ratio_by_date, aes(x = date, y = n)) + 
  geom_line()
```

If we look at the number of contributions made per day, we can see that the 
first contributions came in 2014, but the vast majority have been made in 2016. 

```{r echo=FALSE, warning=FALSE}
ggplot(ratio_by_date, aes(x = date, y = n)) + 
  geom_line() + 
  scale_x_date(limits = as.Date(c("01-01-16", "31-12-16"), "%d-%m-%Y"))
```

If we zoom into the year of the election (2016), we see a clear bimodality in 
the number of contributions. The first peak is in the spring, the second, the 
higher peak can we see at the end of October.

# Univariate Analysis

### What is the structure of your dataset?

After the initial preprocessing (what I mentioned in the previous section) I 
have 1,287,980 observation and 10 variables. These variables are: cmte_id (ID 
of the suporter committee), cand_nm (candidate's name), contbr_nm (contributor's 
name), contbr_city (contributor's city), contbr_zip (contributor's zip code), 
contbr_employer (employer of the contributor), contbr_occupation (occupation of 
the contributor), contb_receipt_amt (amount sent as contribution), contb_receipt_dt 
(date of contribution sent) and election_tp (election for which the contribution
was made). Almost each of the variables are Factor variable and none of them is
ordered factor. I have a date variable and a real valued variable, the amount 
of the contribution. 

Other observation: 

 * There are 25 candidates in the dataset, but four of them received the 95% of 
 the contribution.
 * 29% of the contributions came from retired or unemployed people.
 * Most of the contributors made a small number of donation, but there were 
 a few people who contributed more than 200 times.
 * Most of the contributions were a small amount, and the amount per donation 
 followed a log-normal distribution.

### What is/are the main feature(s) of interest in your dataset?
The main feature of interest for me is the amount of support per candidate. I 
would like to gain some insight and maybe predict, what kind of people supported
which candidate. I will consider only the top 4 candidate because of their 
dominance in the dataset.

The other thing what I want to examine is the contribution for the two finalist 
in function of the date. Is there any trend in support?

### What other features in the dataset do you think will help support your \
investigation into your feature(s) of interest?
I will use the occupation, city, date and committee to make research my idea.

### Did you create any new variables from existing variables in the dataset?
I didn't create any new variable in the dataset, but I created new grouped 
dataframes to count the number of contributions per different categories.

### Of the features you investigated, were there any unusual distributions? \
Did you perform any operations on the data to tidy, adjust, or change the form \
of the data? If so, why did you do this?
I log-transformed the distribution of the amount of support and the number of 
donations made by committees.

I removed the negative donation amounts because I wanted to examine only 
positive support without refunds. There were some values with 0 amount, I dropped
those observations because it was meaningless too.

# Bivariate Plots Section

I want to answer a question using my analysis: "Who supported whom the most?" 
Therefore, I start with a bar chart displaying the sum of each contribution for 
each candidate.

One of my thought was that is it possible, that one candidate receives a large 
number of contribution but the sum of all support is smaller than other candidates'?


```{r echo=FALSE, Bivariate_Plots}
# Create sum plot
ggplot(finData, aes(cand_nm, contb_receipt_amt)) +
  geom_bar(stat = "sum") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

```{r warning=FALSE, echo=FALSE}
mean_by_candidate <- finData %>%
  group_by(cand_nm) %>%
  summarise(num_support = n(), sum_support = sum(contb_receipt_amt)) %>%
  arrange(desc(sum_support))

head(mean_by_candidate)
```

Looking at the bar chart and the summary table, I can't say about the top four 
most supported candidate; their order is the same.

```{r warning=FALSE, echo=FALSE}
ggplot(mean_by_candidate, aes(num_support, sum_support)) +
  geom_point()
```

Looking at the scatterplot, we can recognize two definite and one more potential 
outlier. I searched for the names, and I found that these points are outliers, 
but with the good meaning. They were the most supported candidates. This finding 
is in harmony with my histograms.

Another finding is that the points almost lie on a straight line which would 
mean that the number of contribution and the overall sum correlates to each other.

```{r, warning=FALSE, echo=FALSE}
cor(mean_by_candidate$num_support, mean_by_candidate$sum_support)
```

Another finding is that the points almost lie on a straight line which would 
mean that the number of contribution and the overall sum correlates to each 
other. The value of the correlation coefficient strengthens my theory.

```{r echo=FALSE, warning=FALSE}
# Create sum plot by city
ggplot(finData, aes(contbr_city, contb_receipt_amt)) +
  geom_bar(stat = "sum") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  scale_x_discrete(breaks = seq(0, 2517, 10))
```

From the plot above I can see, that there are four cities which have much more 
support than the others. After displaying the exact values we can see these top
contributor cities.

```{r, warning=FALSE, echo=FALSE}
head(ratio_by_city[order(-ratio_by_city$sum), c("contbr_city", "sum")], n = 10)
```

The numbers prove what we saw in the bar chart. Los Angeles and San Francisco 
raised an order of magnitude larger amount of money than the others.

I was curious about the money collected by people from a specific occupation. I 
have a hypothesis, that a lot of retiree and unemployed people contributed to 
the campaign, I would think that they could not donate so much money personally. 
That's why I compared the average amount of a single donation by occupation.

```{r warning=FALSE, echo=FALSE}
p1 <- ggplot(ratio_by_occupation, aes(contbr_occupation, avg)) + 
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
p2 <- ggplot(ratio_by_occupation, aes(contbr_occupation, sum)) + 
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

grid.arrange(p1, p2, ncol = 2)
```

We can see that - as I expected - retirees raised the largest amount. But the 
average individual contribution of retirees was quite low - only the teachers 
and unemployed people have lower average support.

# Bivariate Analysis

> **Tip**: As before, summarize what you found in your bivariate explorations
here. Use the questions below to guide your discussion.

### Talk about some of the relationships you observed in this part of the \
investigation. How did the feature(s) of interest vary with other features in \
the dataset?

### Did you observe any interesting relationships between the other features \
(not the main feature(s) of interest)?

### What was the strongest relationship you found?


# Multivariate Plots Section

> **Tip**: Now it's time to put everything together. Based on what you found in
the bivariate plots section, create a few multivariate plots to investigate
more complex interactions between variables. Make sure that the plots that you
create here are justified by the plots you explored in the previous section. If
you plan on creating any mathematical models, this is the section where you
will do that.

```{r echo=FALSE, Multivariate_Plots}

```

# Multivariate Analysis

### Talk about some of the relationships you observed in this part of the \
investigation. Were there features that strengthened each other in terms of \
looking at your feature(s) of interest?

### Were there any interesting or surprising interactions between features?

### OPTIONAL: Did you create any models with your dataset? Discuss the \
strengths and limitations of your model.

------

# Final Plots and Summary

> **Tip**: You've done a lot of exploration and have built up an understanding
of the structure of and relationships between the variables in your dataset.
Here, you will select three plots from all of your previous exploration to
present here as a summary of some of your most interesting findings. Make sure
that you have refined your selected plots for good titling, axis labels (with
units), and good aesthetic choices (e.g. color, transparency). After each plot,
make sure you justify why you chose each plot by describing what it shows.

### Plot One
```{r echo=FALSE, Plot_One}

```

### Description One


### Plot Two
```{r echo=FALSE, Plot_Two}

```

### Description Two


### Plot Three
```{r echo=FALSE, Plot_Three}

```

### Description Three

------

# Reflection

> **Tip**: Here's the final step! Reflect on the exploration you performed and
the insights you found. What were some of the struggles that you went through?
What went well? What was surprising? Make sure you include an insight into
future work that could be done with the dataset.

> **Tip**: Don't forget to remove this, and the other **Tip** sections before
saving your final work and knitting the final report!